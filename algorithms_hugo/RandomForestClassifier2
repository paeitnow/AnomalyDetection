import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.offline import init_notebook_mode, iplot
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score
from xgboost import XGBClassifier

# Activation de Plotly hors ligne
init_notebook_mode(connected=True)

# Charger le jeu de données
file_path = r'C:\Tout\Barcelone\annoDet\g.csv'
data = pd.read_csv(file_path)

# Nettoyer les données
data_cleaned = data.dropna(subset=['label']).copy()

# Convertir le timestamp en datetime
data_cleaned['timestamp'] = pd.to_datetime(data_cleaned['timestamp'], unit='s')

# Feature Engineering
data_cleaned['hour'] = data_cleaned['timestamp'].dt.hour
data_cleaned['day_of_week'] = data_cleaned['timestamp'].dt.dayofweek
data_cleaned['day_of_month'] = data_cleaned['timestamp'].dt.day
data_cleaned['month'] = data_cleaned['timestamp'].dt.month

# Normaliser la colonne 'value'
data_cleaned['value_normalized'] = (data_cleaned['value'] - data_cleaned['value'].mean()) / data_cleaned['value'].std()

# Ajouter des statistiques glissantes
data_cleaned['rolling_mean_5'] = data_cleaned['value'].rolling(window=5).mean()
data_cleaned['rolling_std_5'] = data_cleaned['value'].rolling(window=5).std()
data_cleaned['rolling_mean_10'] = data_cleaned['value'].rolling(window=10).mean()
data_cleaned['rolling_std_10'] = data_cleaned['value'].rolling(window=10).std()
data_cleaned.fillna(data_cleaned.mean(), inplace=True)

# Fonctionnalités sélectionnées
features = ['value_normalized', 'hour', 'day_of_week', 'day_of_month', 'month', 
            'rolling_mean_5', 'rolling_std_5', 'rolling_mean_10', 'rolling_std_10']
X = data_cleaned[features]
y = data_cleaned['label'].astype(int)

# Séparer les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardiser les données
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

### Ensembler Random Forest, XGBoost, et Isolation Forest avec ajustements ###
# Modèle 1: Random Forest avec seuil ajusté
rf_model = RandomForestClassifier(n_estimators=200, random_state=42)
rf_model.fit(X_train_scaled, y_train)
rf_proba = rf_model.predict_proba(X_test_scaled)[:, 1]  # Probabilité d'appartenir à la classe 'Anomaly'

# Modèle 2: XGBoost avec ajustement du seuil
xgb_model = XGBClassifier(n_estimators=200, random_state=42)
xgb_model.fit(X_train_scaled, y_train)
xgb_proba = xgb_model.predict_proba(X_test_scaled)[:, 1]

# Modèle 3: Isolation Forest avec un seuil plus bas
iso_model = IsolationForest(contamination=0.05, random_state=42)
iso_model.fit(X_train_scaled)
iso_scores = -iso_model.decision_function(X_test_scaled)  # Négatif pour inverser les scores (plus haut = plus anormal)
iso_threshold = np.percentile(iso_scores, 95)  # Ajuster le seuil à un niveau plus bas pour plus de détections
iso_pred = np.where(iso_scores > iso_threshold, 1, 0)

# Fusion des prédictions basées sur les probabilités moyennes
average_proba = (rf_proba + xgb_proba + iso_pred) / 3
final_pred = (average_proba > 0.3).astype(int)  # Seuil ajusté pour détecter plus d'anomalies

# Ajouter les prédictions au DataFrame principal pour la visualisation
data_cleaned['predicted_anomaly'] = np.nan
data_cleaned.loc[X_test.index, 'predicted_anomaly'] = final_pred

# Évaluation de la performance avec des métriques supplémentaires
performance_report = classification_report(y_test, final_pred, target_names=['Normal', 'Anomaly'])
conf_matrix = confusion_matrix(y_test, final_pred)
roc_auc = roc_auc_score(y_test, average_proba)
pr_auc = average_precision_score(y_test, average_proba)

print("Performance Report:")
print(performance_report)
print("Confusion Matrix:")
print(conf_matrix)
print(f"ROC-AUC Score: {roc_auc:.2f}")
print(f"PR-AUC Score: {pr_auc:.2f}")

# Visualisation interactive avec Plotly
fig = go.Figure()

# Tracer les valeurs normales
fig.add_trace(go.Scatter(x=data_cleaned['timestamp'], y=data_cleaned['value_normalized'],
                         mode='lines', name='Valeur normalisée', line=dict(color='blue', width=2)))

# Ajouter les labels réels (anomalies)
fig.add_trace(go.Scatter(x=data_cleaned['timestamp'][data_cleaned['label'] == 1], 
                         y=data_cleaned['value_normalized'][data_cleaned['label'] == 1],
                         mode='markers', name='Anomalies Réelles', 
                         marker=dict(color='red', size=10, symbol='x')))

# Ajouter les anomalies prédites
fig.add_trace(go.Scatter(x=data_cleaned['timestamp'][data_cleaned['predicted_anomaly'] == 1], 
                         y=data_cleaned['value_normalized'][data_cleaned['predicted_anomaly'] == 1],
                         mode='markers', name='Anomalies Prédites', 
                         marker=dict(color='green', size=8, symbol='circle')))

# Titre et labels des axes
fig.update_layout(title="Détection d'Anomalies - Réelles vs Prédites (Modèle Ensembe)",
                  xaxis_title="Temps", yaxis_title="Valeur Normalisée")

# Affichage du graphique
iplot(fig)
